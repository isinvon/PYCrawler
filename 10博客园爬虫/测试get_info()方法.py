import bs4
import requests

headers = {
    "content-type": "application/json; charset=UTF-8",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36",
    # è¯·å¡«å†™ç™»å½•ä¹‹åçš„cookie
    "cookie": "",
}

def get_info(url, page_end):
    for i in range(1, page_end+1):  # å¾ªç¯é¡µæ•°
        url = url.format(i + 1)  # è¡¥å…¨url
        print(url)
        response = requests.get(url=url, headers=headers)
        content = response.text
        html = content
        soup = bs4.BeautifulSoup(html, 'lxml')
        for num in range(1, 20):
            article = soup.select("article[class='post-item']")[num]
            text = soup.select("div[class='post-item-text']")[num]
            title = text.select("a[class='post-item-title']")[0].text
            link = text.select("a[class='post-item-title']")[0].get("href")
            footer = article.select("footer[class='post-item-foot']")  # æ¯ä¸€ç« çš„è„š
            author = footer[0].select("a span")[0].text  # ä½œè€…
            like = footer[0].select("a span")[1].text  # å–œæ¬¢
            comment = footer[0].select("a span")[2].text  # è¯„è®º
            look = footer[0].select("a span")[3].text  # è§‚çœ‹

            print("ğŸ˜Š" + title + "\n"
                  + "   ç‚¹èµ:" + like + " è¯„è®º:" + comment + "è§‚çœ‹:" + look + " ä½œè€…:" + author + "\n"
                  + "   => " + link + "\n"
                  + "--------------------------")


if __name__ == '__main__':
    url = "https://www.cnblogs.com/#p5"  # åé¢æ˜¯æ•°å­—
    page_end = 2
    print(type(page_end))
    get_info(url, page_end)